**Blockchain Analysis Implementation:**
Introduction
Financial technology has had a profound positive impact on the financial services industry. However, amidst such technological innovation and unbridled growth, fraudsters have been able to identify and exploit gaps. In essence, as technology develops at pace, fraudsters find new ways to cheat the system through adaptive methods. Internal bank fraud is a particularly complex problem to solve, as those who commit this type of fraud do so from a trusted position inside the bank which they work for. Moreover, from the bank’s perspective, they assume that there are sufficient preventative measures in place. 
The issue is, though, the employees entrusted with power over financial systems and databases have a deep understanding of how they can be manipulated. Of the various ways bank employees can commit internal fraud, transaction reversals and account manipulation are the most difficult to detect. Our implementation nullifies both scenarios, utilising an immutable blockchain that records bank employee access attempts as a transaction. 

Results
Task A: Total Accounts and Dictionary Key Comparison.
To determine the number of accounts in the dataset, we first ensured there were no null values then printed the length of inputs in the loan accounts number column. This step was important as failing to check for null values could have skewed our data and impeded the accuracy and validity of our implementation and analysis. Next, we used an if else statement to iterate through all rows and columns in the data frame, checking if the keys in each dictionary of each account were identical or not. The results confirmed that all keys were identical.
Task B: Hash Value Comparison.
In Task B, I hashed the value of three accounts using SHA 256-bit hashing algorithm, strengthening the data’s integrity and security. This encoding is pivotal to achieve tamper-proof resistance – in blockchains, as we’ll discuss later, when data accessed, a new hash value is created. To test our hashing had worked, we wrote a conditional statement that compared the hash values we’d created. The results showed that we’d successfully hashed the values, as when we ran the statement, the system was able to detect identical hashes and non-identical hashes.
Task C: Blockchain Implementation.
In Task C1.1 I created a function (create_block) to return PoW, hashing, variables and a dictionary holding block data, index, timestamp, PoW, and, importantly, the hash of the previous block. As we’ll discuss later, each time we add new blocks to the chain, this function is called to ensure that the genesis block (when created) is included in the chain. We achieved this by creating a (create_chain) function in C1.2, which appends the create_block function to the chain.
By calling both the create_chain and create_block functions in Task C2, users of the system can create a genesis block. Though, rather than have the user call the functions via Python syntax, we implemented conditional statements to prompt the user with a question ‘Do you wish to create a genesis block?’ – the user can create a genesis block by simply answering yes. If they answer no, then we inform them a genesis block has not been created to avoid confusion.
In Task C3 I created a (mine_block) function that takes loan_account_number as a parameter and returns loan start data from the associated df column. Here, we used exceptional errors, so that if the user inputs an invalid loan account number they are prompted to input a valid one. Additional measures such as throttling threshold attempts could be introduced here to mitigate brute force attacks. In valid attempts, new blocks are created using a conditional if else statement. The test results done on single user accounts proved successful. 
Though if a user wanted to add multiple blocks, this function could not be used, though we added this functionality in by creating a (simulation_function) in Task C4, that takes a random 120 number of accounts and calls the mine_block function, adding multiple blocks to the chain in a single function call.
Then in Task C5, the simulation_2 function simulates accessing a specified number of random account numbers from the data frame with a given latency and measures the time it takes to add them to the blockchain. The main_function function serves as the central control, allowing users to perform various tasks according to their preferences. It integrates functions from Task A, B, C, and simulations, providing a comprehensive overview of the blockchain implementation.

Figure:1 Simulation_2 results with latency of 10 seconds and 20 seconds.


Notes: On the X-axis total number of mined blocks with 10-seconds and 20-seconds latency in shown and on the Y-axis shows the total time taken in seconds to record all the blocks in the blockchain.


Figure:2 Simulation_2 results 
Notes: On X-axis total number of blocked mined into the blockchain are shown and on the y-axis the average time taken to mine each individual block with 10 seconds and 20 seconds latency is shown.

When calculating the average time per block creation, I found that at 20 seconds latency, block creation increased slightly as more blocks were created. On the other hand, I found that increasing the number of blocks at 10-second latency resulted in a relatively higher decrease in block creation time. As seen in the graph comparison, there is a noticeable decrease in average block creation time at 10-second latency, the impact at 20-second latency is negligible. 

Critical discussion
Our implementation currently stores users’ data on-chain. Whilst our implementation satisfied certain requirements, such as providing security and audibility of users accessing account details, storing this data on-chain raises considerations. Firstly, the cost of computing and storing data on-chain is relatively higher than off-chain. In addition, as new blocks are mined, the computational complexity required to mine new blocks increases. 
In a proof-of-work system such as ours, the additional amount of compute required to scale the chain to accommodate the bank’s future transaction data may lead to high costs. 
Storing user data on-chain breaks GDPR convention, as users have the right to destroy their data stored on third-party databases upon request. Our implementation does not allow for this. If we were to deploy this implementation in a jurisdiction in which GDPR is enforced, we could choose from a couple of different options. First, we may decide to implement hybrid smart contracts (HSCs). These HSCs combine off-chain scalability and privacy with on-chain immutability and tamper resistance.
Another way is through zero-knowledge protocols using a ZK rollup scaling solution. 
In doing so, we would be able to batch multiple transactions together, compute and store them off-chain, but record the occurrence on-chain. This is achieved through complex cryptography that essentially proves statement ‘X’ is true (on-chain data entry) based on statement ‘Y’ (off-chain transaction), without specifically revealing any sensitive information. 
Though, it should be note that is we opted for either of these methods, we would need to integrate either with off-chain oracles or another network, which both present potential security risks and technologically challenging implementations which require interoperability. 
To achieve some level of interoperability, we’ll need to consider connections via servers, APIs, networks, or oracles. These each come with their own benefits and risks. For instance, APIs would allow for easy data migration and large dataset storage in the cloud. However, hackers often target API connections as point of vulnerability, by either accessing API keys, launching DoS attacks, or MITM attacks. Thus, if we were to choose this method, we could utilise an asymmetric cryptography messaging system which encrypts and decrypts data in and out of transit. 
The last, and arguably biggest criticism of our implementation is that there is a single point of failure, as the network’s security is upheld by one node. Aside from immutability, the concept of decentralisation is often seen as a core value proposition of blockchains. In essence, blockchain networks increase decentralisation by increasing the number of nodes in the network, avoiding risks associated with a single point of failure or a malicious node, strengthening the network’s security in hacks, and validating blocks.
Conclusion
In conclusion, I have imported and conducted preliminary checks on data formats and content, to ensure accurate implementation and analysis, generated hash values for various accounts and checked if they matched, utilised functions to create a genesis block and initiate the blockchain. Simulated storing user data access attempts as immutable transaction entries running a simulation that selects random accounts and appends them to the chain, calling create_block function created earlier to add new blocks. 
Finally, modelled latency against number of blocks and found that in low latency networks, average block creation time decreases as the network as more blocks are added, whilst in higher latency networks, the time to create a single block increased as more blocks were added. 
The implementation provides value to banks as an extra security measure against internal bank fraud, as employees cannot reverse transactions or manipulate accounts details. In addition, by adding exemption rules that record failed access attempts in human readable text, we’ve enhanced the audibility of our implementation so that relevant stakeholders can complete the relevant checks. 
Further usability improvements were made in UI, wherein the end user can interact with our network in pain text, via pre-set prompts set by us. Despite our success, we acknowledge that there are inherent limitations. Securing user data in a regulatory-compliant could be a challenge without shifting some computation and/or storage off-chain. However, in moving off-chain, we would need to interact with potential weak points where hackers may strike. Finally, if we are to scale this network, additional nodes would help bolster its security, resilience, and decentralisation.
